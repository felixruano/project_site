<!DOCTYPE HTML>
<!--
	Prologue by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Predicting Food Inspection Outcomes of Chicago Restaurants</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
	</head>
	<body>

		<!-- Header -->
			<div id="header">

				<div class="top">

					<!-- Logo -->
						<div id="logo">
							<h1 id="title"></h1>
						</div>

					<!-- Nav -->
						<nav id="nav">
							<!--

								Prologue's nav expects links in one of two formats:

								1. Hash link (scrolls to a different section within the page)

								   <li><a href="#foobar" id="foobar-link" class="icon fa-whatever-icon-you-want skel-layers-ignoreHref"><span class="label">Foobar</span></a></li>

								2. Standard link (sends the user to another page/site)

								   <li><a href="http://foobar.tld" id="foobar-link" class="icon fa-whatever-icon-you-want"><span class="label">Foobar</span></a></li>

							-->
							<ul>
								<li><a href="#intro" id="intro-link" class="skel-layers-ignoreHref"><span class="icon fa-home">Intro</span></a></li>
								<li><a href="#background" id="background-link" class="skel-layers-ignoreHref"><span class="icon fa-th">Background</span></a></li>
								<li><a href="#predictors" id="predictors-link" class="skel-layers-ignoreHref"><span class="icon fa-cogs">Predictors</span></a></li>
								<li><a href="#model" id="model-link" class="skel-layers-ignoreHref"><span class="icon fa-filter">Model Selection</span></a></li>
								<li><a href="#biblio" id="biblio-link" class="skel-layers-ignoreHref"><span class="icon fa-book">Bibliography</span></a></li>
							</ul>
						</nav>

				</div>

				<div class="bottom">

					<!-- Social Icons -->
						<ul class="icons">
							<li><a href="#" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="#" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
							<li><a href="#" class="icon fa-github"><span class="label">Github</span></a></li>
							<li><a href="#" class="icon fa-dribbble"><span class="label">Dribbble</span></a></li>
							<li><a href="#" class="icon fa-envelope"><span class="label">Email</span></a></li>
						</ul>

				</div>

			</div>

		<!-- Main -->
			<div id="main">

				<!-- Intro -->
					<section id="intro" class="one dark cover">
						<div class="container">

							<header>
								<h2 class="alt">Predicting Food Inspection Outcomes
								<br> of Chicago Restaurants</h2>
								<h4>Evan Brown, Felix Ruano, Gil Wassermann
								<br />Data Science, Fall 2016</h4>
							</header>

							<footer>
								<a href="#background" class="button scrolly">View Project</a>
							</footer>

						</div>
					</section>

				<!-- Background -->
					<section id="background" class="two">
						<div class="container">

							<header>
								<h2>Background</h2>
							</header>

							<p>In 2014, Chicago’s Department of Innovation and Technology and Allstate’s Quantitative Research & Analytics came together in order to create a model to use publicly available data to predict food facility inspection outcomes. The project was motivated by the staggering statistic that assessing around 16,000 food establishments was tasked to only 36 inspectors. Before this project, food inspections were scheduled in a quasi-random way, the only criterion of which was that each facility was visited in the city-mandated time-frame. While this system ensured that every facility was checked, there was a very real possibility that an establishment with a critical health code violation could continue to operate for a long stretch of time, simply due to the scheduling of inspections. Given the potential for severe illness, Chicago rightly identified this as a public heath issue and turned to data science to solve this problem.</p>

							<p>The goal of the project was to devise a statistically predictive and robust model that could identify the establishments with the highest potential for violating critical health codes. The most likely potential offenders could then be scheduled for inspection and barred from distriution first, minimizing the amount of time the public is exposed to potentially hazardous foodstuffs.</p>

							<p>The outcome of the project was quite staggering. According to the Chicago/Allstate project's website the number of establishments with critical violations caught in a two month period increased from 55% to 69% through use of the data-driven workflow. Another impressive statistic is the establishments with critical violations were, on average caught about a week earlier.Although Chicago/Allstate project yielded amazing results, we are going to try our hand at this project. Hopefully, by using different predictor variables and employing different statistucal techniques we can propose an alternative model.</p>

						</div>
					</section>

				<!-- Predictors -->
					<section id="predictors" class="three">
						<div class="container">

							<header>
								<h2>Predictors</h2>
							</header>

							<p>One of the most interesting aspects of the Chicago/Allstate project were the plethora of different, and seemingly unrelated predictors that were leveraged by their model. Therefore predictor selection was a key component of our project.</p>

							<header>
								<h3>Weather</h3>
							</header>

							<p>Chicago is the Windy City. It can also get excruciatingly cold. One could imagine that restaurant employees would be less than thrilled to perform necessary hygiene proceedures in these conditions. Also, it might be possible that the inspectors themselves are less likely to make site visits in these conditions, which could induce lax behaviour on the part of the establishment owners.</p>

							<p>While maximum and minimum past temperatures are useful metrics, we need a robust method in order to predict future temperatures as a function of inspection dates. Thankfully, temperatures are cyclical, which allows us to fit autoregressive time series models. After investigation of the time series' autocorrelation and partial autocorrelation functions, we fit an AR(12) model to monthly aggregates of the data. Below are our fits:</p>

							<a href="#" class="image centered"><img src="images/arma.png" alt="" /></a>

							<p>An AR(12) model was chosen after examination of an autocorrelogram and partial autocorrelogram of the data. We noticed that the-martial autocorrelogram cut off at the 365th lag of daily data. This suggests that an AR(365) model should be used. However, fitting 365 model parameters would most likely overfit the available data. We needed a more parsimonious solution. We then attempted to implement a SARIMA(0,0,0)x(1,0,0)<sub>365</sub> model in order to reduce the number of fitted coefficients. Here, we ran into a logistical issue, which was that there was no available Python package that could perform this analysis (the SARIMAX model for `statsmodels` is currently under development). As a compromise, we settled on an ARIMA(12,0,0) (another way of describing the AR(12) model) model fit using monthly-aggregated weather data.</p>

							<p>This AR model is useful as it allows us to predict future values of maximum and minimum temperatures.</p>

							<header>
								<h3>Sanitary Code Complaints</h3>
							</header>

							<p>One predictor in our model was created by seeing how many sanitary complaints have been accumulated in each ZIP code using the City of Chicago Open Data Portal since January 1st, 2011. This can be seen as a proxy for the importance placed on hygiene in each neighborhood. NB: This figure has been grouped by ward, which roughly equate to, but are slightly more granular, than ZIP code boundaries.</p>

							<a href="#" class="image centered"><img src="images/combined_sanitation_inspection.png" alt="" /></a>

							<header>
								<h3>Particular Violations</h3>
							</header>

							<p>One important result to come out of the model is that not all violations are created equal. In fact, there are some violations that lead to failed inspections while others do not. The chart below presents the 20 larges negative coefficients of a regularized logistic regression model on the data.</p>

							<a href="#" class="image centered"><img src="images/largenegcoefs.png" alt="" /></a>

							<p>As we can see particular types of violation make up the most negative coefficients, which are those that push the value of a point towards 0, signifying a Fail. Let us look into what some of these complaints entail:
							
							<ul class="list">
								<li>Code 14 : Previous violation uncorrected</li>
								<li>Code 13 : Evidence of rodent or insect infestation, birds, turtles or other animals</li>
								<li>Code 3 : Potentially Hazardous Food does not meet temperature requirement during storage, preparation, display and service</li>
							</ul>

							<p>It is clear that these are particularly critical violations and past incidents of these at a particular restaurant are a clear indication of a lack of a culture of hygiene.</p>


							<header>
								<h3>Type of Inspection</h3>
							</header>

							<p>Another key component of our model is the type of inspection that is being carried out. The chart below presents the most positive coefficients of a regularized logistic regression model on the data.</p>

							<a href="#" class="image centered"><img src="images/largeposcoefs.png" alt="" /></a>

							<p>One thing that is made clear from this graph is that facilities which are being reinspected are more likely to pass a subsequent inspection. This is probably due to the fact that these restaurants have been goaded into more hygienic practices through a Fail or a Pass with Conditions. We can also see particular area codes here, showing how our location data is affecting the model.</p>

							<header>
								<h3>Information Decay</h3>
							</header>

							<p>In appraoching this project, it is necessary to consider the possibility that the amount of information one can infer from a restaurant's inspection results decays with time. This makes intuituve sense as any human reader would place a higher weight on more recent information than older information.</p>

							<p>We used the following two weighting systems (normalized to be in the range 0 to 1) for each inspection day in order to discount past observations. Linearly weighted information decay sees an identical drop in information after each successive day whereas the exponentially weighted information decay sees an increasing amount of information decay for each successive day. Here, the halflife of the decay is one year.</p>

							<a href="#" class="image centered"><img src="images/decay.png" alt="" /></a>

							<header>
								<h3>Labels</h3>
							</header>

							<p>Just as a quick overview of our dataset, here is a pie chart showing the breakdown of the observed inspection results. For our three-class models each of these segments is represented by a different class. In our two-class models, Pass with Conditions is termed as a Fail.</p>

							<script type="text/javascript" src="https://www.gstatic.com/charts/loader.js"></script>
       						<div id="piechart" style="width: 900px; height: 500px;"></div>				

						</div>
					</section>

				<!-- Model Selection -->
					<section id="model" class="two">
						<div class="container">

							<header>
								<h2>Model Selection</h2>
							</header>

							<p>There were three main models that we identified and investigated for this project. These were a Logistic Regression, a Multiclass Logistic Regression (where we made a third class for Pass with Conditions) and a Random Forest. The latter model formed the foundation of the Chicago/Allstate model. Tuning these models with five-fold cross-validation and the evaluating the results yields the following:</p>

							<table cellspacing='0'> <!-- cellspacing='0' is important, must stay -->

								<!-- Table Header -->
								<thead>
								<tr>
									<th>Category</th>
									<th>Logistic Regression</th>
									<th>Random Forest</th>
								</tr>
								</thead>
								<!-- Table Header -->

								<!-- Table Body -->
								<tbody>

									<tr>
										<td>True Positive</td>
										<td>66.6%</td>
										<td>67.9%</td>
									</tr><!-- Table Row -->

									<tr class="even">
										<td>False Negative</td>
										<td>2.7%</td>
										<td>1.4%</td>
									</tr><!-- Darker Table Row -->

									<tr>
										<td>True Negative</td>
										<td>26.0%</td>
										<td>25.0%</td>
									</tr>

									<tr class="even">
										<td>False Positive</td>
										<td>4.7%</td>
										<td>5.7%</td>
									</tr>

								</tbody>

								<!-- Table Body -->

							</table>
							<br>

							<header>
								<h3>Metrics</h3>
							</header>

							<p>For this project, we selected models based on metrics that are more granular than an accuracy score. For the purposes of this question, the two types of misclassification are not equivalent.</p>

							<p>For the case of the false negative, let us imagine the outcome of a restaurant that has been predicted to fail, but actually passes. As a result of this model, an inspector would be sent to this facility quickly and then be able to ascertain that the establishment poses no health risk. The potential downside of this is unecessary expenditure of resources.</p>

							<p>For the case of the false positive, we see a very different story. This type of restaurant would be predicted to pass, but are actually falling foul of a critical violation. A facility in this position would be a low priority inspection target, and therefore would be visited later. In this extra time taken to inspect the facility, they could diseminate potentially hazardous foods to the population.</p>

							<p>In light of this we have selected our model to decrease the number of false positives in the model under five-fold cross-validation.</p>

							<header>
								<h3>Information Decay</h3>
							</header>

							<p>Including weighting schemes in our model led to a trade-off. In sklearn, for a Logistic Regression, there is no solver that allows LASSO regularization as well as attaching weights to the samples. We then attemped to fit the previously tuned Random Forest a freshly tuned Ridge Regularized Logistic Regression to the data. While the majority of the higher-level scores were comparable, in incorporating both linear and exponential decay we increased the number of false positives in our predicted values under five-fold cross-validation. Our analysis yielded the following results:</p>

							<table cellspacing='0'> <!-- cellspacing='0' is important, must stay -->

								<!-- Table Header -->
								<thead>
								<tr>
									<th>Category</th>
									<th>Logistic Regression</th>
									<th>Random Forest</th>
								</tr>
								</thead>
								<!-- Table Header -->

								<!-- Table Body -->
								<tbody>

									<tr>
										<td>True Positive</td>
										<td>66.7%</td>
										<td>67.6%</td>
									</tr><!-- Table Row -->

									<tr class="even">
										<td>False Negative</td>
										<td>2.6%</td>
										<td>1.7%</td>
									</tr><!-- Darker Table Row -->

									<tr>
										<td>True Negative</td>
										<td>25.4%</td>
										<td>24.7%</td>
									</tr>

									<tr class="even">
										<td>False Positive</td>
										<td>5.3%</td>
										<td>6.0%</td>
									</tr>

								</tbody>

								<!-- Table Body -->

							</table>
							<br>

							<header>
								<h3>Final Model</h3>
							</header>

							<p>In light of the above results, we can conclude that the most effective model to use in this scenario is the tuned Logistic Regression. There are several reasons for this:</p>

							<ul class="list">
								<li>The model is easily interpretable. The values of the coefficients can be used to explain the importance of different predictors to policy-makers in order to justify budget allocations.</li>

								<li>The model takes in a large number of predictors. LASSO regularization reduces the number of predictors used in order to suppress noise from unimportant predictors.</li>

								<li>There is likely to be a response to the data-driven workflow from facility operators. This model is lightweight enough to be refit easily to accomodate this response.</li>

								<li>Shown to be less prone to overfitting than the Random Forest model when applied to the whole dataset.</li>
							</ul>
							

						</div>
					</section>

				<!-- Bibliography, Links and Further Reading -->
					<section id="biblio" class="three">
						<div class="container">

							<header>
								<h2>Bibliography, Links and Further Reading</h2>
							</header>

							<p>
							<a href="https://chicago.github.io/food-inspections-evaluation/" class="button">Chicago/Allstate project</a>
							</p>

							<p>
							<a href="https://github.com/Chicago/food-inspections-evaluation" class="button">Open source code in R for the Chicago/Allstate project</a>
							</p>

							<p>
							<a href="http://www.citylab.com/cityfixer/2016/01/chicago-is-predicting-food-safety-violations-why-arent-other-cities/422511/" class="button">Article about the Chicago/Allstate project</a>
							</p>

							<p>
							<a href="https://data.cityofchicago.org/" class="button">City of Chicago Open Data Portal</a>
							</p>

			</div>

		<!-- Footer -->
			<div id="footer">

				<!-- Copyright -->
					<ul class="copyright">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollzer.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>